{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "x=torch.ones(1)\n",
    "b=torch.rand(1,requires_grad=True)\n",
    "w=torch.rand(1,requires_grad=True)\n",
    "y=w*x\n",
    "z=y+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf,y.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7020], grad_fn=<MulBackward0>),\n",
       " tensor([0.9657], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward0 at 0x7fdd57230910>, 0),\n",
       " (<AccumulateGrad at 0x7fdd57230a90>, 0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.], requires_grad=True), tensor([1.], grad_fn=<NegBackward>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def abs(x):\n",
    "    if x.data[0]>0 :return x\n",
    "    else :return -x\n",
    "x=Variable(-1*torch.ones(1),requires_grad=True)\n",
    "y=abs(x)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 6., 3., 2.]), tensor(6., grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    result=1\n",
    "    for ii in x:\n",
    "        if ii>0:result=ii*result\n",
    "    return result\n",
    "x=Variable(torch.arange(-2,4,1.0),requires_grad=True)\n",
    "y=f(x)\n",
    "y.backward()\n",
    "x.grad,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Variable(torch.ones(1))\n",
    "w=Variable(torch.rand(1),requires_grad=True)\n",
    "y=x*w\n",
    "x.requires_grad,y.requires_grad,z.requires_grad,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9875, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Variable(torch.ones(3),requires_grad=True)\n",
    "w=Variable(torch.rand(3),requires_grad=True)\n",
    "y=x*w\n",
    "z=y.sum()\n",
    "print(z)\n",
    "x.requires_grad,w.requires_grad,y.requires_grad,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4415, 0.9311, 0.6149]), tensor([1., 1., 1.]), None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()\n",
    "x.grad,w.grad,y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Variable(torch.ones(3),requires_grad=True)\n",
    "w=Variable(torch.rand(3),requires_grad=True)\n",
    "y=x*w\n",
    "z=y.sum()\n",
    "torch.autograd.grad(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y的梯度： \r\n",
      " tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "def variable_hook(grad):\n",
    "    print('y的梯度： \\r\\n',grad)\n",
    "x=Variable(torch.ones(3),requires_grad=True)\n",
    "w=Variable(torch.rand(3),requires_grad=True)\n",
    "y=x*w\n",
    "hook_handle=y.register_hook(variable_hook)\n",
    "z=y.sum()\n",
    "z.backward()\n",
    "hook_handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.], requires_grad=True),\n",
       " tensor([0., 3., 8.], grad_fn=<AddBackward0>),\n",
       " tensor(11., grad_fn=<SumBackward0>),\n",
       " tensor([2., 4., 6.]),\n",
       " None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Variable(torch.arange(0,3,1.0),requires_grad=True)\n",
    "y=x**2+2*x\n",
    "z=y.sum()\n",
    "z.backward()\n",
    "x,y,z,x.grad,y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2.], requires_grad=True),\n",
       " tensor([0., 3., 8.], grad_fn=<AddBackward0>),\n",
       " tensor(11., grad_fn=<SumBackward0>),\n",
       " tensor([2., 4., 6.]),\n",
       " None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=Variable(torch.arange(0,3,1.0),requires_grad=True)\n",
    "y=x**2+2*x\n",
    "z=y.sum()\n",
    "y.backward(torch.ones(3))\n",
    "x,y,z,x.grad,y.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
